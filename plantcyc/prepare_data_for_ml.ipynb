{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Metabolite</th>\n",
       "      <th>Pathway ID</th>\n",
       "      <th>CAMALEXIN-SYN</th>\n",
       "      <th>NONMEVIPP-PWY</th>\n",
       "      <th>PWY-1187</th>\n",
       "      <th>PWY-1901</th>\n",
       "      <th>PWY-2002</th>\n",
       "      <th>PWY-2083</th>\n",
       "      <th>...</th>\n",
       "      <th>PWY18C3-9</th>\n",
       "      <th>PWY1F-823</th>\n",
       "      <th>PWY4FS-17</th>\n",
       "      <th>PWYQT-4433</th>\n",
       "      <th>PWYQT-4450</th>\n",
       "      <th>PWYQT-4471</th>\n",
       "      <th>PWYQT-4472</th>\n",
       "      <th>PWYQT-4473</th>\n",
       "      <th>PWYQT-4474</th>\n",
       "      <th>PWYQT-4475</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&amp;Delta;&lt;sup&gt;24-25&lt;/sup&gt;-sitosterol</td>\n",
       "      <td>CCC(CC[C@@H](C)[C@H]3(CC[C@H]4([C@@H]2(C\\C=C1(...</td>\n",
       "      <td>CPD-4142</td>\n",
       "      <td>['PWY-2541']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&amp;Delta;&lt;sup&gt;9&lt;/sup&gt;-tetrahydrocannabinol</td>\n",
       "      <td>CCCCCC1(\\C=C(C2(\\[C@@H]3(\\C=C(C)/CC[C@@H](C(C)...</td>\n",
       "      <td>CPD-7172</td>\n",
       "      <td>['PWY-5140']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&amp;Delta;&lt;sup&gt;9&lt;/sup&gt;-tetrahydrocannabinolate</td>\n",
       "      <td>CCCCCC1(\\C(\\C([O-])=O)=C(C2(\\[C@@H]3(\\C=C(C)/C...</td>\n",
       "      <td>CPD-7169</td>\n",
       "      <td>['PWY-5140']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&amp;alpha;-3',4'-anhydrovinblastine</td>\n",
       "      <td>CCC7(\\C[NH+]6(CCC8(\\C9(\\C(\\NC(/[C@@](C(=O)OC)(...</td>\n",
       "      <td>CPD-13001</td>\n",
       "      <td>['PWY-5292']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;alpha;-3',4'-anhydrovinblastine radical</td>\n",
       "      <td>CCC7(\\C[NH+]6(CCC8(\\C9(\\C(\\NC(/[C@@](C(=O)OC)(...</td>\n",
       "      <td>CPD-21576</td>\n",
       "      <td>['PWY-5292']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>zealexin A3</td>\n",
       "      <td>CC2(C)([C@H](O)C(/[C@@H]1(C/C=C(CC1)/C([O-])=O...</td>\n",
       "      <td>CPD-13571</td>\n",
       "      <td>['PWY-6888']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>zealexin A4</td>\n",
       "      <td>CC2(C)(C(=O)C(/[C@@H]1(C/C=C(CC1)/C([O-])=O))=...</td>\n",
       "      <td>CPD-21541</td>\n",
       "      <td>['PWY-6888']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>zealexin B1</td>\n",
       "      <td>CC2(C)(CC(/C1(\\CCC(/C([O-])=O)=C\\C=1))=C\\CC2)</td>\n",
       "      <td>CPD-13572</td>\n",
       "      <td>['PWY-6888']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>zealexin C3</td>\n",
       "      <td>CC2(C)([C@H](O)C(/C1(\\C=C/C(/C([O-])=O)=C\\C=1)...</td>\n",
       "      <td>CPD-21269</td>\n",
       "      <td>['PWY-6888']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>zeaxanthin</td>\n",
       "      <td>CC(/C=C/C=C(C)/C=C/C1(/C(C)(C)C[C@@H](CC(/C)=1...</td>\n",
       "      <td>CPD1F-130</td>\n",
       "      <td>['PWY-5397', 'PWY-5288']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name   \n",
       "0              &Delta;<sup>24-25</sup>-sitosterol  \\\n",
       "1        &Delta;<sup>9</sup>-tetrahydrocannabinol   \n",
       "2     &Delta;<sup>9</sup>-tetrahydrocannabinolate   \n",
       "3                &alpha;-3',4'-anhydrovinblastine   \n",
       "4        &alpha;-3',4'-anhydrovinblastine radical   \n",
       "...                                           ...   \n",
       "1795                                  zealexin A3   \n",
       "1796                                  zealexin A4   \n",
       "1797                                  zealexin B1   \n",
       "1798                                  zealexin C3   \n",
       "1799                                   zeaxanthin   \n",
       "\n",
       "                                                 SMILES Metabolite   \n",
       "0     CCC(CC[C@@H](C)[C@H]3(CC[C@H]4([C@@H]2(C\\C=C1(...   CPD-4142  \\\n",
       "1     CCCCCC1(\\C=C(C2(\\[C@@H]3(\\C=C(C)/CC[C@@H](C(C)...   CPD-7172   \n",
       "2     CCCCCC1(\\C(\\C([O-])=O)=C(C2(\\[C@@H]3(\\C=C(C)/C...   CPD-7169   \n",
       "3     CCC7(\\C[NH+]6(CCC8(\\C9(\\C(\\NC(/[C@@](C(=O)OC)(...  CPD-13001   \n",
       "4     CCC7(\\C[NH+]6(CCC8(\\C9(\\C(\\NC(/[C@@](C(=O)OC)(...  CPD-21576   \n",
       "...                                                 ...        ...   \n",
       "1795  CC2(C)([C@H](O)C(/[C@@H]1(C/C=C(CC1)/C([O-])=O...  CPD-13571   \n",
       "1796  CC2(C)(C(=O)C(/[C@@H]1(C/C=C(CC1)/C([O-])=O))=...  CPD-21541   \n",
       "1797      CC2(C)(CC(/C1(\\CCC(/C([O-])=O)=C\\C=1))=C\\CC2)  CPD-13572   \n",
       "1798  CC2(C)([C@H](O)C(/C1(\\C=C/C(/C([O-])=O)=C\\C=1)...  CPD-21269   \n",
       "1799  CC(/C=C/C=C(C)/C=C/C1(/C(C)(C)C[C@@H](CC(/C)=1...  CPD1F-130   \n",
       "\n",
       "                    Pathway ID  CAMALEXIN-SYN  NONMEVIPP-PWY  PWY-1187   \n",
       "0                 ['PWY-2541']              0              0         0  \\\n",
       "1                 ['PWY-5140']              0              0         0   \n",
       "2                 ['PWY-5140']              0              0         0   \n",
       "3                 ['PWY-5292']              0              0         0   \n",
       "4                 ['PWY-5292']              0              0         0   \n",
       "...                        ...            ...            ...       ...   \n",
       "1795              ['PWY-6888']              0              0         0   \n",
       "1796              ['PWY-6888']              0              0         0   \n",
       "1797              ['PWY-6888']              0              0         0   \n",
       "1798              ['PWY-6888']              0              0         0   \n",
       "1799  ['PWY-5397', 'PWY-5288']              0              0         0   \n",
       "\n",
       "      PWY-1901  PWY-2002  PWY-2083  ...  PWY18C3-9  PWY1F-823  PWY4FS-17   \n",
       "0            0         0         0  ...          0          0          0  \\\n",
       "1            0         0         0  ...          0          0          0   \n",
       "2            0         0         0  ...          0          0          0   \n",
       "3            0         0         0  ...          0          0          0   \n",
       "4            0         0         0  ...          0          0          0   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1795         0         0         0  ...          0          0          0   \n",
       "1796         0         0         0  ...          0          0          0   \n",
       "1797         0         0         0  ...          0          0          0   \n",
       "1798         0         0         0  ...          0          0          0   \n",
       "1799         0         0         0  ...          0          0          0   \n",
       "\n",
       "      PWYQT-4433  PWYQT-4450  PWYQT-4471  PWYQT-4472  PWYQT-4473  PWYQT-4474   \n",
       "0              0           0           0           0           0           0  \\\n",
       "1              0           0           0           0           0           0   \n",
       "2              0           0           0           0           0           0   \n",
       "3              0           0           0           0           0           0   \n",
       "4              0           0           0           0           0           0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1795           0           0           0           0           0           0   \n",
       "1796           0           0           0           0           0           0   \n",
       "1797           0           0           0           0           0           0   \n",
       "1798           0           0           0           0           0           0   \n",
       "1799           0           0           0           0           0           0   \n",
       "\n",
       "      PWYQT-4475  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "1795           0  \n",
       "1796           0  \n",
       "1797           0  \n",
       "1798           0  \n",
       "1799           0  \n",
       "\n",
       "[1800 rows x 274 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plantcyc_pathways = pd.read_csv(\"plant_cyc_pathways_w_labels.csv\")\n",
    "plantcyc_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcapela/miniforge3/envs/deepmol/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[10:16:07] Conflicting single bond directions around double bond at index 17.\n",
      "[10:16:07]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 12.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 17.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 17.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 17.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: CC(C)=CCNC3(/N=C\\N=C1(C(/N=C\\N1[C@@H]2(O[C@H](COP(=O)([O-])O[a\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'CC(C)=CCNC3(/N=C\\N=C1(C(/N=C\\N1[C@@H]2(O[C@H](COP(=O)([O-])O[a' for input: 'CC(C)=CCNC3(/N=C\\N=C1(C(/N=C\\N1[C@@H]2(O[C@H](COP(=O)([O-])O[a'\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 12.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 17.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 17.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 17.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 12.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 17.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C3(C(/[R2])=C([R1])/C(/[C@H]1(OC2(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@H]1O)=2)))=C([R5])\\C(/[R4])=3)[R3]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C3(C(/[R2])=C([R1])/C(/[C@H]1(OC2(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@H]1O)=2)))=C([R5])\\C(/[R4])=3)[R3]' for input: 'C3(C(/[R2])=C([R1])/C(/[C@H]1(OC2(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@H]1O)=2)))=C([R5])\\C(/[R4])=3)[R3]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C(O)[C@@H]4([C@@H](O)[C@H](O)[C@@H](O)[C@H](OC1(\\C(/[R3])=C([R4])/C(\\[R5])=C(C(\\[R1])=1)/[C@H]2(OC3(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@H]2O)=3))))O4)\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C(O)[C@@H]4([C@@H](O)[C@H](O)[C@@H](O)[C@H](OC1(\\C(/[R3])=C([R4])/C(\\[R5])=C(C(\\[R1])=1)/[C@H]2(OC3(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@H]2O)=3))))O4)' for input: 'C(O)[C@@H]4([C@@H](O)[C@H](O)[C@@H](O)[C@H](OC1(\\C(/[R3])=C([R4])/C(\\[R5])=C(C(\\[R1])=1)/[C@H]2(OC3(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@H]2O)=3))))O4)'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C3(C(/[R2])=C([R1])/C(/[C@H]1(OC2(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@@H]1O)=2)))=C([R5])\\C(/[R4])=3)[R3]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C3(C(/[R2])=C([R1])/C(/[C@H]1(OC2(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@@H]1O)=2)))=C([R5])\\C(/[R4])=3)[R3]' for input: 'C3(C(/[R2])=C([R1])/C(/[C@H]1(OC2(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@@H]1O)=2)))=C([R5])\\C(/[R4])=3)[R3]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C(O)[C@@H]4([C@@H](O)[C@H](O)[C@@H](O)[C@H](OC1(\\C(/[R3])=C([R4])/C(\\[R5])=C(C(\\[R1])=1)/[C@H]2(OC3(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@@H]2O)=3))))O4)\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C(O)[C@@H]4([C@@H](O)[C@H](O)[C@@H](O)[C@H](OC1(\\C(/[R3])=C([R4])/C(\\[R5])=C(C(\\[R1])=1)/[C@H]2(OC3(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@@H]2O)=3))))O4)' for input: 'C(O)[C@@H]4([C@@H](O)[C@H](O)[C@@H](O)[C@H](OC1(\\C(/[R3])=C([R4])/C(\\[R5])=C(C(\\[R1])=1)/[C@H]2(OC3(\\C(/[R9])=C([R8])/C(\\[R7])=C([R6])\\C(/C[C@@H]2O)=3))))O4)'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C3([R3])(C(/[R2])=C([R1])/C(/[C@@H]1([C@@H](O)[C@@H](O)C2(/C(\\[R6])=C([R7])\\C(/[R8])=C([R9])/C(/O1)=2)))=C([R5])\\C(/[R4])=3)\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C3([R3])(C(/[R2])=C([R1])/C(/[C@@H]1([C@@H](O)[C@@H](O)C2(/C(\\[R6])=C([R7])\\C(/[R8])=C([R9])/C(/O1)=2)))=C([R5])\\C(/[R4])=3)' for input: 'C3([R3])(C(/[R2])=C([R1])/C(/[C@@H]1([C@@H](O)[C@@H](O)C2(/C(\\[R6])=C([R7])\\C(/[R8])=C([R9])/C(/O1)=2)))=C([R5])\\C(/[R4])=3)'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C1(=C(C(\\[R5])=C(C(/[R1])=C([R2])/1)/C2(/OC3(\\C(/[C@H](O)C(/O)=2)=C([R6])/C(\\[R7])=C([R8])\\C(/[R9])=3)))[R4])[R3]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C1(=C(C(\\[R5])=C(C(/[R1])=C([R2])/1)/C2(/OC3(\\C(/[C@H](O)C(/O)=2)=C([R6])/C(\\[R7])=C([R8])\\C(/[R9])=3)))[R4])[R3]' for input: 'C1(=C(C(\\[R5])=C(C(/[R1])=C([R2])/1)/C2(/OC3(\\C(/[C@H](O)C(/O)=2)=C([R6])/C(\\[R7])=C([R8])\\C(/[R9])=3)))[R4])[R3]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C(OC(=O)[R1])[C@H](COP(=O)([O-])O[C@H]1([C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@@H](O)1))OC(=O)[R2]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C(OC(=O)[R1])[C@H](COP(=O)([O-])O[C@H]1([C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@@H](O)1))OC(=O)[R2]' for input: 'C(OC(=O)[R1])[C@H](COP(=O)([O-])O[C@H]1([C@H](O)[C@@H](O)[C@H](O)[C@@H](O)[C@@H](O)1))OC(=O)[R2]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C(OC(=O)[R1])[C@H](COP([O-])(=O)O[C@@H]1([C@H](O)[C@H](O)[C@@H](OP(=O)([O-])[O-])[C@H](OP(=O)([O-])[O-])[C@@H](O)1))OC(=O)[R2]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C(OC(=O)[R1])[C@H](COP([O-])(=O)O[C@@H]1([C@H](O)[C@H](O)[C@@H](OP(=O)([O-])[O-])[C@H](OP(=O)([O-])[O-])[C@@H](O)1))OC(=O)[R2]' for input: 'C(OC(=O)[R1])[C@H](COP([O-])(=O)O[C@@H]1([C@H](O)[C@H](O)[C@@H](OP(=O)([O-])[O-])[C@H](OP(=O)([O-])[O-])[C@@H](O)1))OC(=O)[R2]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C(OC(=O)[R1])[C@H](COP(=O)([O-])O[C@@H]1([C@H](O)[C@H](O)[C@@H](OP([O-])(=O)[O-])[C@H](O)[C@@H](O)1))OC(=O)[R2]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C(OC(=O)[R1])[C@H](COP(=O)([O-])O[C@@H]1([C@H](O)[C@H](O)[C@@H](OP([O-])(=O)[O-])[C@H](O)[C@@H](O)1))OC(=O)[R2]' for input: 'C(OC(=O)[R1])[C@H](COP(=O)([O-])O[C@@H]1([C@H](O)[C@H](O)[C@@H](OP([O-])(=O)[O-])[C@H](O)[C@@H](O)1))OC(=O)[R2]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C(OC(=O)[R1])[C@H](COP(=O)([O-])O[C@@H]1([C@H](O)[C@H](O)[C@@H](O)[C@H](OP(=O)([O-])[O-])[C@@H](O)1))OC(=O)[R2]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C(OC(=O)[R1])[C@H](COP(=O)([O-])O[C@@H]1([C@H](O)[C@H](O)[C@@H](O)[C@H](OP(=O)([O-])[O-])[C@@H](O)1))OC(=O)[R2]' for input: 'C(OC(=O)[R1])[C@H](COP(=O)([O-])O[C@@H]1([C@H](O)[C@H](O)[C@@H](O)[C@H](OP(=O)([O-])[O-])[C@@H](O)1))OC(=O)[R2]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: O=[a\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'O=[a' for input: 'O=[a'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: [R]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES '[R]' for input: '[R]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C3([R3])(C(/[R4])=C([R5])/C(/C1(/OC2(/C(\\[R9])=C([R8])\\C(/[R7])=C([R6])/C(/C(=O)C(/O)=1)=2)))=C([R1])\\C(/[R2])=3)\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C3([R3])(C(/[R4])=C([R5])/C(/C1(/OC2(/C(\\[R9])=C([R8])\\C(/[R7])=C([R6])/C(/C(=O)C(/O)=1)=2)))=C([R1])\\C(/[R2])=3)' for input: 'C3([R3])(C(/[R4])=C([R5])/C(/C1(/OC2(/C(\\[R9])=C([R8])\\C(/[R7])=C([R6])/C(/C(=O)C(/O)=1)=2)))=C([R1])\\C(/[R2])=3)'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C(O)[C@@H]1([C@@H](O)[C@H](O)[C@@H](O)[C@@H](O1)OC3(\\C(=O)C4(\\C(\\OC(\\C2(/C(\\[R1])=C([R2])\\C(/[R3])=C([R4])/C(\\[R5])=2))=3)=C([R9])/C(\\[R8])=C([R7])\\C(/[R6])=4)))\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C(O)[C@@H]1([C@@H](O)[C@H](O)[C@@H](O)[C@@H](O1)OC3(\\C(=O)C4(\\C(\\OC(\\C2(/C(\\[R1])=C([R2])\\C(/[R3])=C([R4])/C(\\[R5])=2))=3)=C([R9])/C(\\[R8])=C([R7])\\C(/[R6])=4)))' for input: 'C(O)[C@@H]1([C@@H](O)[C@H](O)[C@@H](O)[C@@H](O1)OC3(\\C(=O)C4(\\C(\\OC(\\C2(/C(\\[R1])=C([R2])\\C(/[R3])=C([R4])/C(\\[R5])=2))=3)=C([R9])/C(\\[R8])=C([R7])\\C(/[R6])=4)))'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C6(C(/[R2])=C([R1])/C(/C4(OC5(\\C(/C1(C3(/C(\\[R6])=C([R7])\\C(/[R8])=C/C(/OC(C1O)C2(\\C(/[R1])=C([R2])/C(\\[R3])=C([R4])\\C(/[R5])=2))=3)))=C([R8])/C(\\[R7])=C([R6])\\C(/CC4O)=5)))=C([R5])\\C(/[R4])=6)[R3]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C6(C(/[R2])=C([R1])/C(/C4(OC5(\\C(/C1(C3(/C(\\[R6])=C([R7])\\C(/[R8])=C/C(/OC(C1O)C2(\\C(/[R1])=C([R2])/C(\\[R3])=C([R4])\\C(/[R5])=2))=3)))=C([R8])/C(\\[R7])=C([R6])\\C(/CC4O)=5)))=C([R5])\\C(/[R4])=6)[R3]' for input: 'C6(C(/[R2])=C([R1])/C(/C4(OC5(\\C(/C1(C3(/C(\\[R6])=C([R7])\\C(/[R8])=C/C(/OC(C1O)C2(\\C(/[R1])=C([R2])/C(\\[R3])=C([R4])\\C(/[R5])=2))=3)))=C([R8])/C(\\[R7])=C([R6])\\C(/CC4O)=5)))=C([R5])\\C(/[R4])=6)[R3]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: C1(=C(C(\\[R5])=C(C(/[R1])=C([R2])/1)/C2(C(/O)=C\\C3(\\C(\\[O+]=2)=C([R9])/C(\\[R8])=C([R7])\\C(/[R6])=3)))[R4])[R3]\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'C1(=C(C(\\[R5])=C(C(/[R1])=C([R2])/1)/C2(C(/O)=C\\C3(\\C(\\[O+]=2)=C([R9])/C(\\[R8])=C([R7])\\C(/[R6])=3)))[R4])[R3]' for input: 'C1(=C(C(\\[R5])=C(C(/[R1])=C([R2])/1)/C2(C(/O)=C\\C3(\\C(\\[O+]=2)=C([R9])/C(\\[R8])=C([R7])\\C(/[R6])=3)))[R4])[R3]'\n",
      "[10:16:08] SMILES Parse Error: syntax error while parsing: CC(\\CO)=C\\CNC3(/N=C\\N=C1(C(/N=C\\N1[C@@H]2(O[C@H](COP(=O)([O-])O[a\n",
      "[10:16:08] SMILES Parse Error: Failed parsing SMILES 'CC(\\CO)=C\\CNC3(/N=C\\N=C1(C(/N=C\\N1[C@@H]2(O[C@H](COP(=O)([O-])O[a' for input: 'CC(\\CO)=C\\CNC3(/N=C\\N=C1(C(/N=C\\N1[C@@H]2(O[C@H](COP(=O)([O-])O[a'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 10:16:08,418 — INFO — Assuming multitask since y has more than one dimension. If otherwise, explicitly set the mode to 'classification' or 'regression'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:16:08] Conflicting single bond directions around double bond at index 12.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[10:16:08] Conflicting single bond directions around double bond at index 17.\n",
      "[10:16:08]   BondStereo set to STEREONONE and single bond directions set to NONE.\n"
     ]
    }
   ],
   "source": [
    "from deepmol.loaders import CSVLoader\n",
    "\n",
    "dataset = pd.read_csv(\"plant_cyc_pathways_w_labels.csv\", nrows=2)\n",
    "labels = dataset.columns[4:]\n",
    "# LOAD THE DATA\n",
    "loader = CSVLoader('plant_cyc_pathways_w_labels.csv',\n",
    "                   smiles_field='SMILES',labels_fields=labels)\n",
    "dataset = loader.create_dataset(sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-28 10:16:15,166 — INFO — Mols_shape: (1782,)\n",
      "2025-05-28 10:16:15,169 — INFO — Features_shape: None\n",
      "2025-05-28 10:16:15,170 — INFO — Labels_shape: (1782, 270)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1782,), None, (1782, 270))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmol.splitters import MultiTaskStratifiedSplitter\n",
    "\n",
    "new_splits = [[], [], [], [], []]\n",
    "\n",
    "for i in range(5):\n",
    "    seed = i\n",
    "    datasets = MultiTaskStratifiedSplitter().k_fold_split(dataset, k=5, seed=seed)\n",
    "    for train_dataset, test_dataset in datasets:\n",
    "        train_dataset, validation_dataset = MultiTaskStratifiedSplitter().train_test_split(train_dataset, frac_train=0.8, seed=seed)\n",
    "        new_splits[i].append((train_dataset, validation_dataset, test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(<deepmol.datasets.datasets.SmilesDataset at 0x7f840da593a0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e7a60>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee340>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e7b20>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e5b50>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee3a0>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e7a90>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d75c400>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee400>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e5490>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d75c4c0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee490>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d763c40>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d758f70>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee4f0>)],\n",
       " [(<deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e9d60>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821dcefac0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee6d0>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ea490>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f82f4ed5550>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee760>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e9520>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e73d0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee7c0>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f82f438d910>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821dd1d670>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee820>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e7250>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e5bb0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6ee880>)],\n",
       " [(<deepmol.datasets.datasets.SmilesDataset at 0x7f821d785130>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d77e1f0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d7789a0>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d7851c0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d793af0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778a00>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d785100>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d78f160>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778a60>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d7932e0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d78bcd0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778af0>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d78b9a0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d7906a0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778b50>)],\n",
       " [(<deepmol.datasets.datasets.SmilesDataset at 0x7f821d78e400>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f840e828cd0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778c70>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d78eaf0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821dd1d700>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778cd0>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d785b80>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d7931f0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778d60>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d793490>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d77e8e0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778dc0>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821dd1dd00>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d77e580>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778e20>)],\n",
       " [(<deepmol.datasets.datasets.SmilesDataset at 0x7f821d793f40>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778ca0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778f40>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e5940>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e5730>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778fd0>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e58e0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d6e5430>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d718040>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d793a90>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d7781c0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d7180d0>),\n",
       "  (<deepmol.datasets.datasets.SmilesDataset at 0x7f821d778df0>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d778d00>,\n",
       "   <deepmol.datasets.datasets.SmilesDataset at 0x7f821d718070>)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'splits.pkl'\n",
    "\n",
    "# Write the data to a file using pickle\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(new_splits, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "\n",
    "filename = 'splits.pkl'\n",
    "\n",
    "# Read the data from the file using pickle\n",
    "with open(filename, 'rb') as file:\n",
    "    datasets = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepmol.compound_featurization import LLM\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "from deepmol.standardizer import ChEMBLStandardizer\n",
    "\n",
    "from deepmol.tokenizers import NPBERTTokenizer\n",
    "\n",
    "transformer = LLM(model_path=\"NPBERT\", model=BertModel, config_class=BertConfig,\n",
    "                          tokenizer=NPBERTTokenizer(vocab_file=os.path.join(\"NPBERT\", \"vocab.txt\")), device=\"cuda:0\")\n",
    "\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = datasets[0][0]\n",
    "train_dataset = train_dataset.merge([validation_dataset, test_dataset])\n",
    "ChEMBLStandardizer().standardize(train_dataset, inplace=True)\n",
    "# Featurize the datasets\n",
    "transformer.featurize(train_dataset, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary\n",
    "data_dict = {id_: x for id_, x in zip(train_dataset.ids, train_dataset.X)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to pickle\n",
    "import pickle\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'np_bert.pkl'\n",
    "\n",
    "# Write the data to a file using pickle\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(data_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to pickle\n",
    "import pickle\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'np_bert.pkl'\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open(filename, 'rb') as file:\n",
    "    np_bert = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def featurize_dataset(dataset, np_bert):\n",
    "    features = []\n",
    "    for id_ in dataset.ids:\n",
    "        features.append(np_bert[id_])\n",
    "    features = np.array(features)\n",
    "    dataset._X = features\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_splits = [[], [], [], [], []]\n",
    "\n",
    "for i in range(5):\n",
    "    for train_dataset, validation_dataset, test_dataset in datasets[i]:\n",
    "        train_dataset = featurize_dataset(train_dataset, np_bert)\n",
    "        validation_dataset = featurize_dataset(validation_dataset, np_bert)\n",
    "        test_dataset = featurize_dataset(test_dataset, np_bert)\n",
    "        new_splits[i].append((train_dataset, validation_dataset, test_dataset))\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'splits_npbert.pkl'\n",
    "# Write the data to a file using pickle\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(new_splits, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModernBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "/home/jcapela/.local/share/mamba/envs/np_benchmark/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-05 15:10:23.703982: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-05 15:10:23.704030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-05 15:10:23.705513: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-05 15:10:23.713269: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-05 15:10:24.513637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jcapela/.local/share/mamba/envs/np_benchmark/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "/home/jcapela/.local/share/mamba/envs/np_benchmark/lib/python3.10/site-packages/deepmol/compound_featurization/__init__.py:20: UserWarning: Mol2Vec not available. Please install it to use it. (pip install git+https://github.com/samoturk/mol2vec#egg=mol2vec)\n",
      "  warnings.warn(\"Mol2Vec not available. Please install it to use it. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-05 15:10:30,339 — ERROR — Features are not the same length/type... Recalculate features for all inputs!\n",
      "2025-06-05 15:10:30,343 — ERROR — Features are not the same length/type... Recalculate features for all inputs!\n",
      "2025-06-05 15:10:30,346 — INFO — Standardizer ChEMBLStandardizer initialized with -1 jobs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ChEMBLStandardizer: 100%|██████████| 1782/1782 [00:12<00:00, 144.97it/s]\n",
      "100%|██████████| 1782/1782 [01:02<00:00, 28.46it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# open pickle file\n",
    "# Specify the filename\n",
    "filename = 'splits.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "    \n",
    "\n",
    "import os\n",
    "from deepmol.compound_featurization import LLM\n",
    "from transformers import ModernBertModel, ModernBertConfig\n",
    "\n",
    "transformer = LLM(model_path=\"../ModernBERT\", model=ModernBertModel, config_class=ModernBertConfig, device=\"cuda:0\")\n",
    "\n",
    "from deepmol.standardizer import ChEMBLStandardizer\n",
    "train_dataset, validation_dataset, test_dataset = loaded_data[0][0]\n",
    "train_dataset = train_dataset.merge([validation_dataset, test_dataset])\n",
    "ChEMBLStandardizer().standardize(train_dataset, inplace=True)\n",
    "# Featurize the datasets\n",
    "transformer.featurize(train_dataset, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary\n",
    "data_dict = {id_: x for id_, x in zip(train_dataset.ids, train_dataset.X)}\n",
    "\n",
    "# to pickle\n",
    "import pickle\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'modern_bert.pkl'\n",
    "\n",
    "# Write the data to a file using pickle\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(data_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the pickle file\n",
    "with open(filename, 'rb') as file:\n",
    "    np_bert = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def featurize_dataset(dataset, np_bert):\n",
    "    features = []\n",
    "    for id_ in dataset.ids:\n",
    "        features.append(np_bert[id_])\n",
    "    features = np.array(features)\n",
    "    dataset._X = features\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_splits = [[], [], [], [], []]\n",
    "\n",
    "for i in range(5):\n",
    "    for train_dataset, validation_dataset, test_dataset in loaded_data[i]:\n",
    "        train_dataset = featurize_dataset(train_dataset, np_bert)\n",
    "        validation_dataset = featurize_dataset(validation_dataset, np_bert)\n",
    "        test_dataset = featurize_dataset(test_dataset, np_bert)\n",
    "        new_splits[i].append((train_dataset, validation_dataset, test_dataset))\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'splits_modern_bert.pkl'\n",
    "# Write the data to a file using pickle\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(new_splits, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
